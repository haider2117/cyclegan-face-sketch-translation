{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lw4IZLDfFvjH",
        "outputId": "a9e431e5-1b47-4992-d800-a7b7c085407b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Using device: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-52d19a58-8ba8-459e-8105-822474cf2c20\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-52d19a58-8ba8-459e-8105-822474cf2c20\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/almightyj/person-face-sketches\n",
            "License(s): CC0-1.0\n",
            "person-face-sketches.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace /content/dataset/test/photos/10132.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "a\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:49<00:00,  3.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30]  G_loss: 4.5230  D_loss: 0.3930\n",
            "âœ… Saved model checkpoints for epoch 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/30]  G_loss: 3.7817  D_loss: 0.3556\n",
            "âœ… Saved model checkpoints for epoch 2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/30]  G_loss: 3.5065  D_loss: 0.3537\n",
            "âœ… Saved model checkpoints for epoch 3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/30]  G_loss: 3.4470  D_loss: 0.3308\n",
            "âœ… Saved model checkpoints for epoch 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/30]  G_loss: 3.4506  D_loss: 0.3065\n",
            "âœ… Saved model checkpoints for epoch 5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/30]  G_loss: 3.5145  D_loss: 0.2813\n",
            "âœ… Saved model checkpoints for epoch 6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/30]  G_loss: 3.3318  D_loss: 0.3869\n",
            "âœ… Saved model checkpoints for epoch 7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/30]  G_loss: 2.8562  D_loss: 0.3733\n",
            "âœ… Saved model checkpoints for epoch 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/30]  G_loss: 3.0035  D_loss: 0.4035\n",
            "âœ… Saved model checkpoints for epoch 9\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/30]  G_loss: 3.2121  D_loss: 0.2730\n",
            "âœ… Saved model checkpoints for epoch 10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/30]  G_loss: 3.3475  D_loss: 0.2492\n",
            "âœ… Saved model checkpoints for epoch 11\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/30]  G_loss: 3.2698  D_loss: 0.2560\n",
            "âœ… Saved model checkpoints for epoch 12\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/30]  G_loss: 3.3066  D_loss: 0.2331\n",
            "âœ… Saved model checkpoints for epoch 13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/30]  G_loss: 3.2872  D_loss: 0.2291\n",
            "âœ… Saved model checkpoints for epoch 14\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/30]  G_loss: 3.4051  D_loss: 0.1902\n",
            "âœ… Saved model checkpoints for epoch 15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/30]  G_loss: 3.2746  D_loss: 0.2409\n",
            "âœ… Saved model checkpoints for epoch 16\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/30]  G_loss: 2.9437  D_loss: 0.2790\n",
            "âœ… Saved model checkpoints for epoch 17\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/30]  G_loss: 3.1691  D_loss: 0.2274\n",
            "âœ… Saved model checkpoints for epoch 18\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/30]  G_loss: 3.2982  D_loss: 0.1840\n",
            "âœ… Saved model checkpoints for epoch 19\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/30]  G_loss: 3.3654  D_loss: 0.1727\n",
            "âœ… Saved model checkpoints for epoch 20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [21/30]  G_loss: 3.3573  D_loss: 0.1639\n",
            "âœ… Saved model checkpoints for epoch 21\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [22/30]  G_loss: 3.3250  D_loss: 0.1595\n",
            "âœ… Saved model checkpoints for epoch 22\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [23/30]  G_loss: 3.3113  D_loss: 0.2707\n",
            "âœ… Saved model checkpoints for epoch 23\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [24/30]  G_loss: 2.7632  D_loss: 0.2996\n",
            "âœ… Saved model checkpoints for epoch 24\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [25/30]  G_loss: 3.1886  D_loss: 0.1592\n",
            "âœ… Saved model checkpoints for epoch 25\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [26/30]  G_loss: 3.2969  D_loss: 0.1439\n",
            "âœ… Saved model checkpoints for epoch 26\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [27/30]  G_loss: 3.2809  D_loss: 0.1489\n",
            "âœ… Saved model checkpoints for epoch 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:50<00:00,  3.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [28/30]  G_loss: 3.2513  D_loss: 0.1522\n",
            "âœ… Saved model checkpoints for epoch 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [29/30]  G_loss: 3.2307  D_loss: 0.1538\n",
            "âœ… Saved model checkpoints for epoch 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [04:51<00:00,  3.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [30/30]  G_loss: 3.2004  D_loss: 0.1502\n",
            "âœ… Saved model checkpoints for epoch 30\n",
            "âœ… Output generated and saved at /content/output_face.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# =====================================\n",
        "# ðŸ”¹ 1. Setup Environment\n",
        "# =====================================\n",
        "!pip install -q kaggle torch torchvision matplotlib tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, utils\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"âœ… Using device:\", device)\n",
        "\n",
        "# =====================================\n",
        "# ðŸ”¹ 2. Load Dataset from Kaggle\n",
        "# =====================================\n",
        "!mkdir -p ~/.kaggle\n",
        "from google.colab import files\n",
        "files.upload()  # Upload your kaggle.json here manually once\n",
        "\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d almightyj/person-face-sketches -p /content/\n",
        "!unzip -q /content/person-face-sketches.zip -d /content/dataset\n",
        "\n",
        "# =====================================\n",
        "# ðŸ”¹ 3. Define Transforms and Dataloaders\n",
        "# =====================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform=None, max_images=None):\n",
        "        self.transform = transform\n",
        "        self.files_A = sorted(os.listdir(os.path.join(root, 'photos')))\n",
        "        self.files_B = sorted(os.listdir(os.path.join(root, 'sketches')))\n",
        "        if max_images:\n",
        "            self.files_A = self.files_A[:max_images]\n",
        "            self.files_B = self.files_B[:max_images]\n",
        "        self.root_A = os.path.join(root, 'photos')\n",
        "        self.root_B = os.path.join(root, 'sketches')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        from PIL import Image\n",
        "        img_A = Image.open(os.path.join(self.root_A, self.files_A[index % len(self.files_A)])).convert('RGB')\n",
        "        img_B = Image.open(os.path.join(self.root_B, self.files_B[index % len(self.files_B)])).convert('RGB')\n",
        "        if self.transform:\n",
        "            img_A = self.transform(img_A)\n",
        "            img_B = self.transform(img_B)\n",
        "        return {'A': img_A, 'B': img_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.files_A), len(self.files_B))\n",
        "\n",
        "train_dataset = ImageDataset('/content/dataset/train', transform=transform, max_images=1000)\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# =====================================\n",
        "# ðŸ”¹ 4. Define CycleGAN Models\n",
        "# =====================================\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        )\n",
        "    def forward(self, x): return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_blocks=6):\n",
        "        super().__init__()\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, 64, 7, 1, 3),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "        in_channels = 64\n",
        "        for out_channels in [128, 256]:\n",
        "            model += [\n",
        "                nn.Conv2d(in_channels, out_channels, 3, 2, 1),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.ReLU(True)\n",
        "            ]\n",
        "            in_channels = out_channels\n",
        "        for _ in range(n_blocks):\n",
        "            model += [ResnetBlock(in_channels)]\n",
        "        for out_channels in [128, 64]:\n",
        "            model += [\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, 3, 2, 1, 1),\n",
        "                nn.InstanceNorm2d(out_channels),\n",
        "                nn.ReLU(True)\n",
        "            ]\n",
        "            in_channels = out_channels\n",
        "        model += [nn.Conv2d(in_channels, output_nc, 7, 1, 3), nn.Tanh()]\n",
        "        self.model = nn.Sequential(*model)\n",
        "    def forward(self, x): return self.model(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super().__init__()\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, True)\n",
        "        ]\n",
        "        model += [\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, 1, 1),\n",
        "            nn.InstanceNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, True),\n",
        "\n",
        "            nn.Conv2d(512, 1, 4, 1, 1)\n",
        "        ]\n",
        "        self.model = nn.Sequential(*model)\n",
        "    def forward(self, x): return self.model(x)\n",
        "\n",
        "# Instantiate models\n",
        "G_A2B = Generator(3, 3).to(device)\n",
        "G_B2A = Generator(3, 3).to(device)\n",
        "D_A = Discriminator(3).to(device)\n",
        "D_B = Discriminator(3).to(device)\n",
        "\n",
        "# =====================================\n",
        "# ðŸ”¹ 5. Define Losses and Optimizers\n",
        "# =====================================\n",
        "criterion_GAN = nn.MSELoss()\n",
        "criterion_cycle = nn.L1Loss()\n",
        "\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(G_A2B.parameters(), G_B2A.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# =====================================\n",
        "# ðŸ”¹ 6. Training Loop (30 epochs, 1000 samples)\n",
        "# =====================================\n",
        "num_epochs = 30\n",
        "save_path = '/content/drive/MyDrive/cyclegan_checkpoints'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    G_A2B.train(); G_B2A.train()\n",
        "    total_G_loss, total_D_loss = 0, 0\n",
        "\n",
        "    for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\")):\n",
        "        real_A = batch['A'].to(device)\n",
        "        real_B = batch['B'].to(device)\n",
        "\n",
        "        valid = torch.ones((real_A.size(0), 1, 30, 30), device=device)\n",
        "        fake = torch.zeros((real_A.size(0), 1, 30, 30), device=device)\n",
        "\n",
        "        # --- Train Generators ---\n",
        "        optimizer_G.zero_grad()\n",
        "        fake_B = G_A2B(real_A)\n",
        "        fake_A = G_B2A(real_B)\n",
        "\n",
        "        loss_GAN_A2B = criterion_GAN(D_B(fake_B), valid)\n",
        "        loss_GAN_B2A = criterion_GAN(D_A(fake_A), valid)\n",
        "        loss_cycle_A = criterion_cycle(G_B2A(fake_B), real_A)\n",
        "        loss_cycle_B = criterion_cycle(G_A2B(fake_A), real_B)\n",
        "        loss_G = loss_GAN_A2B + loss_GAN_B2A + 10.0 * (loss_cycle_A + loss_cycle_B)\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # --- Train Discriminator A ---\n",
        "        optimizer_D_A.zero_grad()\n",
        "        loss_D_A = (criterion_GAN(D_A(real_A), valid) + criterion_GAN(D_A(fake_A.detach()), fake)) * 0.5\n",
        "        loss_D_A.backward()\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        # --- Train Discriminator B ---\n",
        "        optimizer_D_B.zero_grad()\n",
        "        loss_D_B = (criterion_GAN(D_B(real_B), valid) + criterion_GAN(D_B(fake_B.detach()), fake)) * 0.5\n",
        "        loss_D_B.backward()\n",
        "        optimizer_D_B.step()\n",
        "\n",
        "        total_G_loss += loss_G.item()\n",
        "        total_D_loss += (loss_D_A.item() + loss_D_B.item())\n",
        "\n",
        "    print(f\"Epoch [{epoch}/{num_epochs}]  G_loss: {total_G_loss/len(train_loader):.4f}  D_loss: {total_D_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    # Save checkpoints\n",
        "    torch.save(G_A2B.state_dict(), f\"{save_path}/G_A2B_epoch{epoch}.pth\")\n",
        "    torch.save(G_B2A.state_dict(), f\"{save_path}/G_B2A_epoch{epoch}.pth\")\n",
        "    print(f\"âœ… Saved model checkpoints for epoch {epoch}\")\n",
        "\n",
        "# =====================================\n",
        "# ðŸ”¹ 7. Test Inference Example\n",
        "# =====================================\n",
        "from PIL import Image\n",
        "test_path = '/content/dataset/test/sketches'\n",
        "img = Image.open(os.path.join(test_path, os.listdir(test_path)[0])).convert('RGB')\n",
        "img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "with torch.no_grad():\n",
        "    fake_photo = G_B2A(img_tensor)\n",
        "utils.save_image((fake_photo * 0.5 + 0.5), '/content/output_face.jpg')\n",
        "print(\"âœ… Output generated and saved at /content/output_face.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# ðŸ”¹ CycleGAN Flask UI â€” Modern frontend with side-by-side preview\n",
        "# ============================================================\n",
        "\n",
        "!pip install -q flask flask_cors pyngrok Pillow torchvision torch tqdm opencv-python\n",
        "\n",
        "# --- Imports ---\n",
        "import os, io, base64\n",
        "from PIL import Image\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "import torch, torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# --- Drive mount ---\n",
        "if os.path.exists(\"/content/drive/MyDrive\"):\n",
        "    print(\"âœ… Google Drive already mounted.\")\n",
        "else:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"âœ… Mounted Google Drive.\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ”¹ Model Definitions\n",
        "# ============================================================\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(dim, dim, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 3, 1, 1),\n",
        "            nn.InstanceNorm2d(dim)\n",
        "        )\n",
        "    def forward(self, x): return x + self.block(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_blocks=6):\n",
        "        super().__init__()\n",
        "        model = [\n",
        "            nn.Conv2d(input_nc, 64, 7, 1, 3),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(True)\n",
        "        ]\n",
        "        in_channels = 64\n",
        "        for out_channels in [128, 256]:\n",
        "            model += [nn.Conv2d(in_channels, out_channels, 3, 2, 1),\n",
        "                      nn.InstanceNorm2d(out_channels), nn.ReLU(True)]\n",
        "            in_channels = out_channels\n",
        "        for _ in range(n_blocks):\n",
        "            model += [ResnetBlock(in_channels)]\n",
        "        for out_channels in [128, 64]:\n",
        "            model += [nn.ConvTranspose2d(in_channels, out_channels, 3, 2, 1, 1),\n",
        "                      nn.InstanceNorm2d(out_channels), nn.ReLU(True)]\n",
        "            in_channels = out_channels\n",
        "        model += [nn.Conv2d(in_channels, output_nc, 7, 1, 3), nn.Tanh()]\n",
        "        self.model = nn.Sequential(*model)\n",
        "    def forward(self, x): return self.model(x)\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ”¹ Load trained weights\n",
        "# ============================================================\n",
        "G_A2B_path = \"/content/drive/MyDrive/cyclegan_checkpoints/G_A2B_epoch30.pth\"\n",
        "G_B2A_path = \"/content/drive/MyDrive/cyclegan_checkpoints/G_B2A_epoch30.pth\"\n",
        "\n",
        "G_A2B = Generator(3,3).to(device)\n",
        "G_B2A = Generator(3,3).to(device)\n",
        "\n",
        "def load_model_safe(model, path):\n",
        "    if os.path.exists(path):\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "        model.eval()\n",
        "        print(f\"âœ… Loaded checkpoint: {path}\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Checkpoint not found: {path}\")\n",
        "\n",
        "load_model_safe(G_A2B, G_A2B_path)\n",
        "load_model_safe(G_B2A, G_B2A_path)\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ”¹ Image transforms\n",
        "# ============================================================\n",
        "transform_in = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "])\n",
        "def postprocess_tensor(tensor):\n",
        "    t = tensor.squeeze(0).cpu().detach()\n",
        "    t = (t * 0.5) + 0.5\n",
        "    t = t.clamp(0,1)\n",
        "    return transforms.ToPILImage()(t)\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ”¹ Auto-detect sketch vs photo\n",
        "# ============================================================\n",
        "def detect_sketch_or_photo(pil_img):\n",
        "    img = np.array(pil_img.convert('RGB'))\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    sat_mean = hsv[:,:,1].mean() / 255.0\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    edge_density = edges.mean() / 255.0\n",
        "    if sat_mean < 0.12 and edge_density > 0.02: return 'sketch'\n",
        "    if sat_mean < 0.12: return 'sketch'\n",
        "    return 'photo'\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ”¹ Flask App with better frontend\n",
        "# ============================================================\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "HTML_PAGE = '''\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<meta charset=\"UTF-8\">\n",
        "<title>CycleGAN Face â†” Sketch Converter</title>\n",
        "<style>\n",
        "body {\n",
        "  background: #111827;\n",
        "  color: #fff;\n",
        "  font-family: 'Segoe UI', sans-serif;\n",
        "  text-align: center;\n",
        "  margin: 0; padding: 0;\n",
        "}\n",
        "h2 { margin-top: 30px; color: #60a5fa; }\n",
        ".container {\n",
        "  margin-top: 40px;\n",
        "}\n",
        "input[type=file] {\n",
        "  background: #1f2937;\n",
        "  border: 1px solid #374151;\n",
        "  color: #fff;\n",
        "  padding: 10px;\n",
        "  border-radius: 8px;\n",
        "}\n",
        "button {\n",
        "  background: #3b82f6;\n",
        "  color: #fff;\n",
        "  padding: 10px 20px;\n",
        "  border: none;\n",
        "  border-radius: 8px;\n",
        "  cursor: pointer;\n",
        "  margin-top: 15px;\n",
        "}\n",
        "button:hover { background: #2563eb; }\n",
        ".preview {\n",
        "  display: flex;\n",
        "  justify-content: center;\n",
        "  gap: 20px;\n",
        "  margin-top: 30px;\n",
        "  flex-wrap: wrap;\n",
        "}\n",
        ".preview img {\n",
        "  width: 256px;\n",
        "  height: 256px;\n",
        "  object-fit: cover;\n",
        "  border-radius: 10px;\n",
        "  box-shadow: 0 0 15px rgba(255,255,255,0.1);\n",
        "}\n",
        "</style>\n",
        "</head>\n",
        "<body>\n",
        "  <h2>ðŸŒ€ CycleGAN Face â†” Sketch Converter</h2>\n",
        "  <div class=\"container\">\n",
        "    <input type=\"file\" id=\"imageInput\" accept=\"image/*\">\n",
        "    <br>\n",
        "    <button onclick=\"uploadImage()\">Convert</button>\n",
        "    <div class=\"preview\" id=\"preview\"></div>\n",
        "  </div>\n",
        "<script>\n",
        "async function uploadImage(){\n",
        "  const fileInput = document.getElementById('imageInput');\n",
        "  if (!fileInput.files.length) return alert('Please select an image.');\n",
        "  const formData = new FormData();\n",
        "  formData.append('image', fileInput.files[0]);\n",
        "  const previewDiv = document.getElementById('preview');\n",
        "  previewDiv.innerHTML = '<p>Processing...</p>';\n",
        "  const res = await fetch('/convert', {method: 'POST', body: formData});\n",
        "  const blob = await res.blob();\n",
        "  const convertedUrl = URL.createObjectURL(blob);\n",
        "  const originalUrl = URL.createObjectURL(fileInput.files[0]);\n",
        "  previewDiv.innerHTML = `\n",
        "    <div><h4>Original</h4><img src=\"${originalUrl}\"></div>\n",
        "    <div><h4>Converted</h4><img src=\"${convertedUrl}\"></div>`;\n",
        "}\n",
        "</script>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template_string(HTML_PAGE)\n",
        "\n",
        "@app.route('/convert', methods=['POST'])\n",
        "def convert():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error':'No image uploaded'}), 400\n",
        "    img_file = request.files['image']\n",
        "    img = Image.open(img_file).convert('RGB')\n",
        "    img_type = detect_sketch_or_photo(img)\n",
        "    input_tensor = transform_in(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        output_tensor = G_B2A(input_tensor) if img_type == 'sketch' else G_A2B(input_tensor)\n",
        "    output_img = postprocess_tensor(output_tensor)\n",
        "    buf = io.BytesIO()\n",
        "    output_img.save(buf, format='JPEG')\n",
        "    buf.seek(0)\n",
        "    return buf.getvalue(), 200, {'Content-Type': 'image/jpeg'}\n",
        "\n",
        "# ============================================================\n",
        "# ðŸ”¹ Ngrok + Run\n",
        "# ============================================================\n",
        "!ngrok config add-authtoken 32JOlU24yIl2AfXBgvXLN67t25F_5NwouvyuY2B6BR2HocywU\n",
        "\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\"ðŸ”¥ Public URL: {public_url}\")\n",
        "\n",
        "app.run(port=5000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEGFDp_g4SjX",
        "outputId": "6ae79df0-9ddd-4a9e-8d9c-1477cc8cabe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google Drive already mounted.\n",
            "Using device: cuda\n",
            "âœ… Loaded checkpoint: /content/drive/MyDrive/cyclegan_checkpoints/G_A2B_epoch30.pth\n",
            "âœ… Loaded checkpoint: /content/drive/MyDrive/cyclegan_checkpoints/G_B2A_epoch30.pth\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "ðŸ”¥ Public URL: https://c030d9140c10.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Nov/2025 18:13:07] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Nov/2025 18:13:08] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Nov/2025 18:14:01] \"POST /convert HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Nov/2025 18:16:32] \"POST /convert HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}